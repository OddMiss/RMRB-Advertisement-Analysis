{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The updated code `response.encoding = response.apparent_encoding or response.encoding` works effectively because it addresses two key challenges when dealing with web scraping and HTML parsing: **character encoding** and **HTML structure handling**.\n",
    "\n",
    "### 1. **Character Encoding**\n",
    "Web pages can use different character encodings (like `UTF-8`, `GB2312`, or others), especially for non-Latin scripts like Chinese. If the encoding is not correctly handled, you may encounter garbled text or errors. Here's why the approach works:\n",
    "\n",
    "- **HTTP Response Encoding**:  \n",
    "  When `requests.get(url)` fetches a page, the `response.encoding` property is usually set to the encoding specified in the HTTP headers (`Content-Type`).\n",
    "\n",
    "- **`response.apparent_encoding`**:  \n",
    "  `requests` includes a feature to detect the most likely encoding of the response content if it isn’t explicitly specified. This detection is done using `chardet` or `charset-normalizer`.\n",
    "\n",
    "- **Setting `response.encoding`**:  \n",
    "  By explicitly setting `response.encoding` to `response.apparent_encoding` (if detected), you ensure the text is decoded properly into readable Chinese (or other characters). If `response.apparent_encoding` isn’t available, it defaults to the server-provided encoding.\n",
    "\n",
    "### 2. **HTML Parsing with BeautifulSoup**\n",
    "Once the content is decoded correctly, `BeautifulSoup` can handle and parse the HTML structure effectively. Here's how it works:\n",
    "\n",
    "- **Chinese Text Support**:  \n",
    "  `BeautifulSoup` doesn't require special handling for Chinese or other scripts once the HTML is correctly decoded. It works on the parsed Unicode representation of the content.\n",
    "\n",
    "- **Tag and Text Matching**:  \n",
    "  When you use `soup.find('a', text='PDF下载')`, `BeautifulSoup`:\n",
    "  - Searches for an `<a>` tag where the visible text matches `'PDF下载'`.\n",
    "  - Compares the decoded text (now readable Chinese) to find the desired tag.\n",
    "\n",
    "### Why It Matters\n",
    "If the encoding isn't correctly handled, the Chinese characters (like `PDF下载`) might appear as unreadable symbols (e.g., `æŒ‰è¦ä½¿ç”¨`) in the `response.text`. This would cause the `soup.find` method to fail because it can't match garbled text.\n",
    "\n",
    "### Summary of Why This Works\n",
    "1. **Accurate Encoding Detection**:\n",
    "   - Ensures the response content is decoded correctly, preserving Chinese characters and other special symbols.\n",
    "\n",
    "2. **Robust Parsing**:\n",
    "   - `BeautifulSoup` can reliably locate the desired elements in the properly decoded HTML structure.\n",
    "\n",
    "3. **Seamless Integration**:\n",
    "   - Using libraries like `requests` and `BeautifulSoup` allows for handling encoding and parsing seamlessly, even for non-Latin scripts. \n",
    "\n",
    "This combination makes the script resilient and ensures it works for web pages containing Chinese or other complex character sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Link: http://paper.people.com.cn/rmrb/pc/attachement/202412/25/58d97d37-6229-4f3b-872d-3911f85cb11b.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Function to extract the PDF link from the HTML\n",
    "def get_pdf_link(url):\n",
    "    try:\n",
    "        # Fetch the webpage content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for HTTP request errors\n",
    "\n",
    "        # Properly decode the response content\n",
    "        # Use response.apparent_encoding to handle Chinese characters if needed\n",
    "        response.encoding = response.apparent_encoding or response.encoding\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # print(soup.prettify())\n",
    "        \n",
    "        # Locate the <a> tag with the \"PDF下载\" text\n",
    "        pdf_tag = soup.find('a', string='PDF下载')\n",
    "        if pdf_tag:\n",
    "            # Construct the absolute URL for the PDF link\n",
    "            pdf_url = urljoin(url, pdf_tag['href'])\n",
    "            return pdf_url\n",
    "        else:\n",
    "            return \"PDF link not found.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error occurred: {e}\"\n",
    "\n",
    "# Example usage\n",
    "url = \"http://paper.people.com.cn/rmrb/pc/layout/202412/25/node_01.html\"\n",
    "pdf_link = get_pdf_link(url)\n",
    "print(\"PDF Link:\", pdf_link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
